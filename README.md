# ğŸ¢ Autonomous HDB DeepAgents

**A Multi-Agent Geospatial + Resale-Price Intelligence System for Singapore HDB Search**

This project provides an **autonomous DeepAgent pipeline** that processes natural-language queries like:

- "Find flats near Bukit Batok MRT"
- "Show me 4-room flats in Toa Payoh under 500k"
- "HDB near MRT within 600m with good value picks"

and turns them into:
1. Intent extraction (town, MRT station, flat type, max price, radius)
2. MRT resolver (maps MRT â†’ nearest HDB planning area via MCP SQL tool)
3. Resale flat retrieval via MCP PostgreSQL tools
4. Geospatial enrichment via MCP geospatial-query tools
5. Distance formatting and correction
6. LLM-powered summaries

All orchestrated end-to-end via **DeepAgents + LangGraph**.

---

# ğŸŒ³ Project Structure

```text
autonomous-hdb-deepagents/
â”‚
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ autonomous_hdb_deepagents/
â”‚       â”‚   __init__.py
â”‚       â”‚
â”‚       â”œâ”€â”€ agent/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ cli.py                 # CLI entrypoint (uv run -m autonomous_hdb_deepagents.agent.cli)
â”‚       â”‚   â”œâ”€â”€ deep_agent.py          # DeepAgent factory + LangGraph orchestration pipeline
â”‚       â”‚   â”œâ”€â”€ intent.py              # LLM-powered intent extraction
â”‚       â”‚   â”œâ”€â”€ mrt_resolver.py        # MRT â†’ HDB-town resolver (MCP SQL)
â”‚       â”‚   â”œâ”€â”€ resale.py              # HDB resale SQL query node
â”‚       â”‚   â”œâ”€â”€ mrt.py                 # Geospatial enrichment node
â”‚       â”‚   â”œâ”€â”€ summary.py             # LLM summary generation node
â”‚       â”‚   â”œâ”€â”€ state.py               # PipelineState (Pydantic)
â”‚       â”‚   â”œâ”€â”€ tools.py               # MCP Toolbox loader + caching
â”‚       â”‚   â””â”€â”€ llm.py                 # Shared OpenRouter LLM instance (ChatOpenAI)
â”‚       â”‚
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ api_server.py          # FastAPI server providing /health + /query
â”‚       â”‚   â””â”€â”€ api_server_launch.py   # Standalone launcher with controlled PYTHONPATH
â”‚       â”‚
â”‚       â””â”€â”€ ui/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ gradio_app.py          # Gradio full-screen chat UI with sample questions
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ deepagents-multi-agent.ipynb
â”‚   â”œâ”€â”€ deepagents-sub-agent.ipynb
â”‚   â”œâ”€â”€ deepagents-custom-model.ipynb
â”‚   â””â”€â”€ data-ingestion/
â”‚       â”œâ”€â”€ hdb-existing-building.ipynb
â”‚       â”œâ”€â”€ hdb-property-info.ipynb
â”‚       â”œâ”€â”€ lta-mrt-exits.ipynb
â”‚       â”œâ”€â”€ moe-sg-schools.ipynb
â”‚       â”œâ”€â”€ npark-parks.ipynb
â”‚       â””â”€â”€ onemap-geocoding-cache.ipynb
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ init/                  # Schema + ingestion SQL
â”‚       â”œâ”€â”€ 00_schema.sql
â”‚       â”œâ”€â”€ 01_load_data.sql
â”‚       â””â”€â”€ data/              # Preprocessed CSV/GeoJSON from notebooks
â”‚          â””â”€â”€ *.csv
â”‚
â”œâ”€â”€ tools.yaml
â”œâ”€â”€ start.sh
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

# ğŸ“š Data Ingestion & Processing Notebooks

This project includes a set of **fully reproducible data-ingestion notebooks** located under:
```bash
notebook/data-ingestion/
```

These notebooks document how each official dataset from **data.gov.sg**, **LTA**, **MOE**, **NParks**, and **OneMap** was:
1. Downloaded (CSV/GeoJSON/API)
2. Cleaned
3. Transformed and normalized
4. Converted into SQL-ready tables
5. Inserted into PostgreSQL

These notebooks serve as **transparent documentation** of all preprocessing logic and allow anyone to **rebuild the entire database from scratch**.

## Included Notebooks

| Notebook                      | Purpose                                                                 |
|-------------------------------|-------------------------------------------------------------------------|
| hdb-existing-building.ipynb   | Extracts and processes HDB existing building geometries and metadata.   |
| hdb-property-info.ipynb       | Loads HDB property information dataset and formats it for SQL ingestion.|
| lta-mrt-exits.ipynb           | Processes official LTA MRT exit GeoJSON and creates table-ready geometries. |
| moe-sg-schools.ipynb          | Processes MOE schools master list (locations, categories, addresses).   |
| npark-parks.ipynb             | Loads NParks parks boundaries/points and normalizes names + coordinates.|
| onemap-geocoding-cache.ipynb  | Generates and caches OneMap coordinate lookups to speed up ingestion.   |

# âš™ï¸ Installation

## 1. Install dependencies

```powershell
uv sync
```

## 2. Install in editable mode
```powershell
uv add --dev --editable .
```

Now you can import:
```python
import autonomous_hdb_deepagents
```

# ğŸš€ Running the CLI Agent

## Recommended (module form)
```powershell
uv run -m autonomous_hdb_deepagents.agent.cli "Find flats near Bukit Panjang MRT"
```

## Or direct script path:
```powershell
uv run src/autonomous_hdb_deepagents/agent/cli.py "Find flats near Bukit Panjang MRT"
```

## Example Output
```text
[INTENT] Parsed intent â†’ {'town': None, 'mrt_station': 'Bukit Panjang', 'flat_type': None, 'max_price': None, 'mrt_radius': None}
[MRT-RESOLVE] Resolving MRT station: Bukit Panjang
[MRT-RESOLVE] BP â†’ BUKIT PANJANG
[RESALE] Fetching 4 ROOM in BUKIT PANJANG <= 600000...
[RESALE] Retrieved 30 flats
[MRT] Enriching 30 flats (radius=800)
[MRT] Example: BT PANJANG RING RD â†’ BANKIT LRT STATION (162m)
[SUMMARY] Summarizing 30 flats

=== FINAL RESPONSE ===

### **Flats Near Bukit Panjang MRT: Summary**
...
```

# âš¡ Pipeline Overview (DeepAgents + LangGraph)

## 1ï¸âƒ£ intent_node

Extracts:
- town
- mrt_station
- flat_type
- max_price
- mrt_radius

## 2ï¸âƒ£ mrt_resolve_node

- Calls MCP `get-mrt-towns`
- Resolves `"BB" â†’ "BUKIT BATOK"`
- Auto-sets `town` if missing

## 3ï¸âƒ£ resale_node

Uses MCP SQL tool `list-hdb-flats` to fetch:
- block
- street
- price
- coordinates

Defaults:
- flat_type="4 ROOM"
- max_price=600000
- town="TOA PAYOH" (fallback)

## 4ï¸âƒ£ mrt_node (Geospatial Enrichment)

Uses MCP:
```text
geospatial-query
```

Adds:
- nearest mrt
- distance raw
- formatted distance (e.g., `"367m"`, `"1.1km"`)

Smart unit normalization
- degrees â†’ meters
- km â†’ meters
- meters â†’ meters

## 5ï¸âƒ£ summary_node

LLM produces:
- price range
- closest flats
- best value picks
- meaningful insights

## 6ï¸âƒ£ DeepAgent Orchestrator

Graph:
```text
intent â†’ mrt_resolve â†’ resale â†’ mrt â†’ summary â†’ END
```

# ğŸŒ FastAPI HTTP Server

The API lives under:
```powershell
src/autonomous_hdb_deepagents/api/
```

Start server:
```powershell
uv run python src/autonomous_hdb_deepagents/api/api_server_launch.py
```

Health check
```powershell
curl http://localhost:8000/health
```

Query endpoint (PowerShell-safe):
```powershell
Invoke-RestMethod -Uri "http://localhost:8000/query" -Method Post `
  -Body '{"query":"Find flats near Bukit Batok MRT"}' `
  -ContentType "application/json"

# Sample Outputs
# response
# --------
# ### HDB Flats Near Bukit Batok MRT  â€¦
```

# ğŸ–¥ï¸ Web UI (Gradio) â€” Natural-Language Chat Interface

The project includes a **fully interactive Gradio chat UI** for your autonomous HDB DeepAgent.
This UI is separate from the FastAPI server and can run independently.

## âœ” Features

- Full-screen responsive chat layout
- Sample question buttons
- Built-in DeepAgent orchestration
- Works 100% locally â€” no external server needed
- Runs in its own process

## ğŸš€ Running the Gradio UI

From project root:
```powershell
uv run python src/autonomous_hdb_deepagents/ui/gradio_app.py
```

You will see:
```text
* Running on local URL:  http://0.0.0.0:7860
```

Open this in your browser:
```html
â¡ï¸ http://localhost:7860
```

# ğŸ”§ Required MCP Tools

You must have these MCP tools available:

## 1. Resale lookup
```text
list-hdb-flats
```

## MRT â†’ HDB town mapping
```text
get-mrt-towns
```

## Geospatial nearest-mrt search
```text
geospatial-query
```

Loaded dynamically via:
```python
ToolboxClient("http://127.0.0.1:5000")
```

# ğŸ§  Design Principles
  
âœ” Fully modular agent layers  
âœ” Clear separation of concerns  
âœ” State management via Pydantic  
âœ” LangGraph deterministic pipeline  
âœ” DeepAgent orchestration wrapper  
âœ” Supports CLI, server, and notebook workflows  
âœ” Clean Python package for reuse  

# ğŸš€ Running Autonomous HDB DeepAgents with Docker

This section explains how to run the entire systemâ€”**database, toolbox, backend API, and Gradio UI**â€”using docker-compose.

The final architecture looks like this:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Docker Host         â”‚
â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  PostgreSQL  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€ Loads HDB resale + MRT data on first run
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚            â–²             â”‚
â”‚            â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Toolbox     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€ Local MCP agent for structured SQL/Geo tools
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚            â–²             â”‚
â”‚            â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Backend API  â”‚        â”‚
â”‚  â”‚ (FastAPI)    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚            â–²             â”‚
â”‚            â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Gradio UI   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸ˜ 1. Postgres Setup (Auto-loaded Data)

On **first run**, Postgres will:
  1. Create hdb_database
  2. Install PostGIS
  3. Create all required tables
  4. Auto-ingest all CSVs

## ğŸ§° 2. Toolbox Setup (Local MCP Server)

The Dockerfile:
- Downloads the toolbox binary
- Runs it on port 5000
- Uses `tools.yaml` inside the container

All agents call Toolbox via:
```bash
TOOLBOX_URL=http://localhost:5000
```

## ğŸ–¥ï¸ 3. Backend (FastAPI + Gradio UI)

The backend container exposes:

| Component   | Port |
|-------------|------|
| FastAPI     | 8000 |
| Gradio UI   | 7860 |
| Toolbox API | 5000 |

The start.sh runs these in parallel:
1. Toolbox
2. FastAPI
3. Gradio

## â–¶ï¸ 4. Run Everything

Start environment:
```powershell
docker-compose up
```

After successful boot:
- Gradio UI â†’ http://localhost:7860
- FastAPI docs â†’ http://localhost:8000/docs

## â™»ï¸ 5. Reset Everything (including database)

```powershell
docker-compose down -v
```

This clears Postgres volumes and triggers CSV reload on next start.

## ğŸ“Œ 6. Confirming System Works

### In UI:

You should be able to run:
```text
Find cheapest 5-room flats near Punggol MRT under 600k
```

# ğŸ“Š Data Sources & Citations

This project uses publicly available datasets from Singaporeâ€™s Housing & Development Board (HDB) provided via **data.gov.sg** under the Singapore Open Data Licence.

Please cite the following datasets if you use this project in research, reports, publications, or derivative works:

## APA Citations

- Housing & Development Board. (2016). Resale Flat Prices (Based on Approval Date), 1990â€“1999 (2024) [Dataset]. data.gov.sg.
Retrieved December 7, 2025, from https://data.gov.sg/datasets/d_ebc5ab87086db484f88045b47411ebc5/view

- Housing & Development Board. (2016). Resale Flat Prices (Based on Approval Date), 2000â€“Feb 2012 (2024) [Dataset]. data.gov.sg.
Retrieved December 7, 2025, from https://data.gov.sg/datasets/d_43f493c6c50d54243cc1eab0df142d6a/view

- Housing & Development Board. (2016). Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014 (2024) [Dataset]. data.gov.sg.
Retrieved December 7, 2025, from https://data.gov.sg/datasets/d_2d5ff9ea31397b66239f245f57751537/view

- Housing & Development Board. (2017). Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016 (2024) [Dataset]. data.gov.sg.
Retrieved December 7, 2025, from https://data.gov.sg/datasets/d_ea9ed51da2787afaf8e51f827c304208/view

- Housing & Development Board. (2021). Resale flat prices based on registration date from Jan-2017 onwards (2025) [Dataset]. data.gov.sg.
Retrieved December 7, 2025, from https://data.gov.sg/datasets/d_8b84c4ee58e3cfc0ece0d773c8ca6abc/view

- Housing & Development Board. (2018). HDB Property Information (2025) [Dataset]. data.gov.sg. Retrieved December 7, 2025 from https://data.gov.sg/datasets/d_17f5382f26140b1fdae0ba2ef6239d2f/view

- National Parks Board. (2023). Parks (2025) [Dataset]. data.gov.sg. Retrieved December 7, 2025 from https://data.gov.sg/datasets/d_0542d48f0991541706b58059381a6eca/view

- Ministry of Education. (2017). General information of schools (2025) [Dataset]. data.gov.sg. Retrieved December 7, 2025 from https://data.gov.sg/datasets/d_688b934f82c1059ed0a6993d2a829089/view

- Land Transport Authority. (2019). LTA MRT Station Exit (GEOJSON) (2025) [Dataset]. data.gov.sg. Retrieved December 7, 2025 from https://data.gov.sg/datasets/d_b39d3a0871985372d7e1637193335da5/view

## ğŸ“˜ Notes on Dataset Usage

- Data is provided under the **Singapore Open Data Licence**.
- Users are permitted to **reuse, modify, and redistribute** these datasets.
- Proper **attribution must be given**, as included above.
- This project aggregates, normalizes, and enriches the datasets into a PostgreSQL schema suitable for agent-based geospatial queries.